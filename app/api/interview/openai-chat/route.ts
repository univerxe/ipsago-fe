import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

type DeltaContentChunk = string | { text?: string }

export async function POST(request: NextRequest) {
  try {
    console.log('üì® Received OpenAI interview chat request')
    
    const body = await request.json()
    const { interviewType = 'standard', jobData, userProfile, conversationHistory, userMessage } = body

    console.log('üìù User message:', userMessage.substring(0, 50) + '...')
    console.log('üîë API Key check:', process.env.OPENAI_API_KEY ? 'Found ‚úÖ' : 'Missing ‚ùå')

    if (!process.env.OPENAI_API_KEY) {
      console.error('‚ùå OpenAI API key not configured')
      return NextResponse.json(
        { error: 'OpenAI API key not configured' },
        { status: 500 }
      )
    }

    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    })

    // Get interview type specific instructions
    const getInterviewTypeInstructions = () => {
      if (interviewType === 'personality') {
        return `
**Î©¥Ï†ë Ïú†Ìòï: Ïù∏ÏÑ± Î©¥Ï†ë (Personality Test)**

ÏßÄÏõêÏûêÏùò Ïù∏ÏÑ±, Í∞ÄÏπòÍ¥Ä, ÌñâÎèô, Î¨∏Ìôî Ï†ÅÌï©ÏÑ±ÏùÑ ÌèâÍ∞ÄÌïòÎäî Î©¥Ï†ëÏûÖÎãàÎã§.

**ÏßàÎ¨∏ Ïπ¥ÌÖåÍ≥†Î¶¨:**
1. ÌåÄÏõåÌÅ¨ & ÌòëÏóÖ
2. Í∞àÎì± Ìï¥Í≤∞
3. Î¶¨ÎçîÏã≠ Í≤ΩÌóò
4. Ïä§Ìä∏Î†àÏä§ Í¥ÄÎ¶¨
5. Ïã§Ìå® & ÌïôÏäµ
6. Ïú§Î¶¨Ï†Å ÎîúÎ†àÎßà
7. ÌöåÏÇ¨ Î¨∏Ìôî Ï†ÅÌï©ÏÑ±
8. Ïû•Í∏∞ Ïª§Î¶¨Ïñ¥ Î™©Ìëú

**ÏßàÎ¨∏ Ïä§ÌÉÄÏùº:**
- "~ÌñàÎçò Í≤ΩÌóòÏóê ÎåÄÌï¥ ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî"
- "~ÏùÑ Ïñ¥ÎñªÍ≤å Ï≤òÎ¶¨ÌïòÏÖ®ÎÇòÏöî"
- "~Ìïú ÏÉÅÌô©ÏùÑ ÏÑ§Î™ÖÌï¥ Ï£ºÏÑ∏Ïöî"
- STAR Î∞©Ïãù Ïú†ÎèÑ (Situation, Task, Action, Result)
- Í≥ºÍ±∞ Í≤ΩÌóòÍ≥º ÌñâÎèôÏóê Ï¥àÏ†ê
- Í∞ÄÏπòÍ¥ÄÍ≥º ÎèôÍ∏∞ ÌååÏïÖ
- ÎãµÎ≥ÄÏóê ÎåÄÌï¥ ÍπäÏù¥ ÏûàÍ≤å ÏßàÎ¨∏

**ÏßàÎ¨∏ ÌäπÏßï:**
- Í∞úÎ∞©Ìòï ÏßàÎ¨∏
- Ïã§Ï†ú Í≤ΩÌóò Í∏∞Î∞ò
- ÌñâÎèô Ìå®ÌÑ¥ Ï§ëÏã¨
- ÏßàÎ¨∏Îãπ 2-3Î¨∏Ïû• Ïù¥ÎÇ¥
`
      } else {
        return `
**Î©¥Ï†ë Ïú†Ìòï: Í∏∞Ïà† Î©¥Ï†ë (Technical Interview)**

ÏßÄÏõêÏûêÏùò Í∏∞Ïà†Ï†Å Ïó≠Îüâ, Î¨∏Ï†ú Ìï¥Í≤∞ Îä•Î†•, Ïã§Î¨¥ Í≤ΩÌóòÏùÑ ÌèâÍ∞ÄÌïòÎäî Î©¥Ï†ëÏûÖÎãàÎã§.

**ÏßàÎ¨∏ Ïπ¥ÌÖåÍ≥†Î¶¨:**
1. Í∏∞Ïà† Ïä§ÌÉù Í≤ΩÌóò (${jobData.skills?.join(', ')})
2. ÏãúÏä§ÌÖú ÏïÑÌÇ§ÌÖçÏ≤ò & ÏÑ§Í≥Ñ
3. Î¨∏Ï†ú Ìï¥Í≤∞ Ï†ëÍ∑º Î∞©Ïãù
4. ÏΩîÎìú ÌíàÏßà & ÏµúÏ†ÅÌôî
5. ÎîîÎ≤ÑÍπÖ & Ìä∏Îü¨Î∏îÏäàÌåÖ
6. ÏµúÏã† Í∏∞Ïà† Ìä∏Î†åÎìú & Î≤†Ïä§Ìä∏ ÌîÑÎûôÌã∞Ïä§
7. ÎèÑÍµ¨ & Î∞©Î≤ïÎ°†
8. Í∏∞Ïà†Ï†Å ÏùòÏÇ¨Í≤∞Ï†ï

**ÏßàÎ¨∏ Ïä§ÌÉÄÏùº:**
- "~Î•º Ïñ¥ÎñªÍ≤å Íµ¨ÌòÑÌïòÏÖ®ÎÇòÏöî..."
- "Ïôú ~Î•º ÏÑ†ÌÉùÌïòÏÖ®ÎÇòÏöî..."
- "~Î•º Ïñ¥ÎñªÍ≤å ÏµúÏ†ÅÌôîÌïòÏãúÍ≤†ÏäµÎãàÍπå..."
- "Ïñ¥Îñ§ Î¨∏Ï†úÍ∞Ä ÏûàÏóàÍ≥† Ïñ¥ÎñªÍ≤å Ìï¥Í≤∞ÌïòÏÖ®ÎÇòÏöî..."
- "ÏïÑÌÇ§ÌÖçÏ≤ò Í≤∞Ï†ïÏóê ÎåÄÌï¥ ÏÑ§Î™ÖÌï¥ Ï£ºÏÑ∏Ïöî..."
- Íµ¨Ï≤¥Ï†ÅÏù∏ Í∏∞Ïà† ÏÑ∏Î∂ÄÏÇ¨Ìï≠ ÏöîÏ≤≠
- ÏßÄÌëúÏôÄ Í≤∞Í≥º ÏöîÏ≤≠
- Í∏∞Ïà† ÏÑ†ÌÉùÏóê ÎåÄÌï¥ ÎèÑÏ†ÑÏ†Å ÏßàÎ¨∏
- Trade-offÏóê ÎåÄÌï¥ ÏßàÎ¨∏

**ÏßàÎ¨∏ ÌäπÏßï:**
- Í∏∞Ïà†Ï†ÅÏúºÎ°ú Íµ¨Ï≤¥Ï†Å
- Ïã§Ï†ú Íµ¨ÌòÑÏóê Ï¥àÏ†ê
- Íµ¨Ï≤¥Ï†ÅÏù∏ ÏòàÏãú ÏöîÏ≤≠
- ÏÑ±Îä•Í≥º ÌôïÏû•ÏÑ±Ïóê ÎåÄÌï¥ ÏßàÎ¨∏
- ÏßàÎ¨∏Îãπ 2-3Î¨∏Ïû• Ïù¥ÎÇ¥
`
      }
    }
    
    // Build system message with job and resume context - IN KOREAN
    const systemMessage = `ÎãπÏã†ÏùÄ ${jobData.company}Ïùò ${jobData.title} Ìè¨ÏßÄÏÖòÏóê ÎåÄÌïú Î©¥Ï†ëÏùÑ ÏßÑÌñâÌïòÎäî Ï†ÑÎ¨∏ HR Î©¥Ï†ëÍ¥ÄÏûÖÎãàÎã§.

${getInterviewTypeInstructions()}

**Ï±ÑÏö© Í≥µÍ≥†:**
${jobData.description || 'Ï†ïÎ≥¥ ÏóÜÏùå'}

**ÏöîÍµ¨ Í∏∞Ïà†:**
${jobData.skills?.join(', ') || 'Î™ÖÏãúÎêòÏßÄ ÏïäÏùå'}

**Ï£ºÏöî ÏóÖÎ¨¥:**
${jobData.responsibilities?.slice(0, 3).join('\n') || 'Î™ÖÏãúÎêòÏßÄ ÏïäÏùå'}

**ÏßÄÏõêÏûê Ï†ïÎ≥¥:**
- Ïù¥Î¶Ñ: ${userProfile.fullName || 'ÏßÄÏõêÏûê'}
- Í≤ΩÎ†•: ${userProfile.experience || '0'}ÎÖÑ
- Í∏∞Ïà†: ${userProfile.skills || 'Î™ÖÏãúÎêòÏßÄ ÏïäÏùå'}
- Ìù¨Îßù ÏßÅÎ¨¥: ${userProfile.targetRole || 'Î™ÖÏãúÎêòÏßÄ ÏïäÏùå'}

**Ïù¥Î†•ÏÑú ÎÇ¥Ïö©:**
${userProfile.resumeText ? userProfile.resumeText.substring(0, 2000) : 'Ïù¥Î†•ÏÑú Ï†ïÎ≥¥ ÏóÜÏùå. ÏúÑÏùò Í∏∞Ïà†Í≥º Í≤ΩÎ†• Ï†ïÎ≥¥Î•º ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.'}

**Î©¥Ï†ë ÏßÑÌñâ Î∞©Ïãù:**
1. Ï±ÑÏö© Í≥µÍ≥†ÏôÄ ÏßÄÏõêÏûê Î∞∞Í≤ΩÏùÑ Î∞îÌÉïÏúºÎ°ú Í¥ÄÎ†® ÏßàÎ¨∏
2. Ìïú Î≤àÏóê ÌïòÎÇòÏùò ÏßàÎ¨∏Îßå
3. Ï†ÑÎ¨∏Ï†ÅÏù¥Î©¥ÏÑúÎèÑ ÏπúÍ∑ºÌïòÍ≤å
4. ÏßÄÏõêÏûê ÎãµÎ≥ÄÏóê ÎåÄÌï¥ ÌõÑÏÜç ÏßàÎ¨∏
5. Ïù¥ ÏßÅÎ¨¥Ïóê ÎåÄÌïú Ï†ÅÌï©ÏÑ± ÌèâÍ∞Ä
6. ÎãµÎ≥ÄÏùÄ Í∞ÑÍ≤∞ÌïòÍ≤å (2-3Î¨∏Ïû• Ïù¥ÎÇ¥)
7. ÎãµÎ≥ÄÏóê Îî∞Îùº Ï†êÏßÑÏ†ÅÏúºÎ°ú ÎÇúÏù¥ÎèÑ ÏÉÅÏäπ
8. Î©¥Ï†ë Ïú†ÌòïÏóê Îî∞Îùº Í¥ÄÎ†® ÏòÅÏó≠ Ïª§Î≤Ñ

**Ï§ëÏöî ÏßÄÏπ®:**
- ÌïúÍµ≠ Ï∑®ÏóÖ ÏãúÏû• ÏßÑÏûÖÏùÑ ÏúÑÌïú Î©¥Ï†ë Ïó∞Ïäµ
- ÏßÄÏßÄÏ†ÅÏù¥Í≥† Í≤©Î†§ÌïòÎäî ÌÉúÎèÑ
- Î™ÖÌôïÌïòÍ≥† Íµ¨Ï≤¥Ï†ÅÏù∏ ÏßàÎ¨∏ Ï†úÍ≥µ
- Íµ¨Ï≤¥Ï†ÅÏù∏ ÏòàÏãúÏôÄ ÏÑ∏Î∂ÄÏÇ¨Ìï≠ ÏöîÏ≤≠
- Ïã§Ï†ú Í≤ΩÌóòÏóê Ï¥àÏ†ê
- Î™®Îì† ÏßàÎ¨∏Í≥º ÎãµÎ≥ÄÏùÄ ÌïúÍµ≠Ïñ¥Î°ú ÏßÑÌñâ`

    // Build conversation messages
    const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
      { role: 'system', content: systemMessage },
      ...conversationHistory.map((msg: any) => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      })),
      { role: 'user', content: userMessage }
    ]

    console.log('üöÄ Sending to OpenAI (streaming)...')

    const encoder = new TextEncoder()

    const stream = new ReadableStream({
      async start(controller) {
        try {
          const completion = await openai.chat.completions.create({
            model: 'gpt-4o-mini', // Fast and cost-effective
            messages,
            temperature: 0.7,
            max_tokens: 300,
            stream: true,
          })

          for await (const part of completion) {
            const deltaContent = part.choices?.[0]?.delta?.content
            let contentChunk = ''

            if (typeof deltaContent === 'string') {
              contentChunk = deltaContent
            } else if (Array.isArray(deltaContent)) {
              contentChunk = (deltaContent as DeltaContentChunk[])
                .map((chunk) => (typeof chunk === 'string' ? chunk : chunk?.text ?? ''))
                .join('')
            }

            if (contentChunk) {
              controller.enqueue(
                encoder.encode(`data: ${JSON.stringify({ token: contentChunk })}\n\n`)
              )
            }
          }

          controller.enqueue(
            encoder.encode(
              `data: ${JSON.stringify({ done: true, timestamp: new Date().toISOString() })}\n\n`
            )
          )
          controller.close()
        } catch (streamError: any) {
          console.error('‚ùå Streaming error:', streamError)
          controller.enqueue(
            encoder.encode(
              `data: ${JSON.stringify({ error: streamError?.message || 'Streaming error' })}\n\n`
            )
          )
          controller.close()
        }
      },
    })

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache, no-transform',
        Connection: 'keep-alive',
      },
    })
  } catch (error: any) {
    console.error('‚ùå OpenAI chat error:', error)
    console.error('‚ùå Error message:', error?.message)
    
    return NextResponse.json(
      { 
        error: 'Failed to generate response',
        details: error?.message || 'Unknown error',
      },
      { status: 500 }
    )
  }
}

